{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anti-bestemmie function\n",
    "\n",
    "Actually checkpoint this shit. Not just **one** checkpoint, but as many as you wish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import shutil\n",
    "\n",
    "\n",
    "def checkpoint(notebook_name):\n",
    "    idx = os.listdir().index(notebook_name + '.ipynb')\n",
    "    name = str(datetime.datetime.now())\n",
    "    shutil.copy('./' + notebook_name + '.ipynb', './.ipynb_checkpoints/' + notebook_name + '-' + name + '.ipynb')\n",
    "\n",
    "checkpoint('analysis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actual work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "wd = os.getcwd() + '/'\n",
    "sys.path.append(wd + '../')\n",
    "sys.path.append(wd + '../../')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "from models import Rule\n",
    "\n",
    "from numpy import array\n",
    "from statistics import harmonic_mean\n",
    "\n",
    "# Auto-reload code\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configurations\n",
    "\n",
    "Configurations to run the analysis. They include:\n",
    "- hyperparameters\n",
    "- input folders/files\n",
    "- output folders/files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "datasets = ['adult', 'churn', 'compas', 'german']\n",
    "black_boxes = ['dnn', 'rf']\n",
    "\n",
    "# Logs appendices with template\n",
    "# {$dataset}.{$black box}.{$scoring}.results.json\n",
    "logs_template = '{0}.{1}.{2}.results.json'\n",
    "# {$dataset}.{$adversary}.{$black_box}.{$scoring}.json\n",
    "adversary_logs_template = '{0}.{1}.{2}.{3}.results.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load\n",
    "Load data for the given configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def load(dataset, wp, ws, alpha, beta, maxlen):\n",
    "    template = logs_template.format(dataset)\n",
    "\n",
    "    with open(wd + '../output/' + template, 'r') as log:\n",
    "        results = json.load(log)\n",
    "\n",
    "    run = None\n",
    "    for entry in results['runs']:\n",
    "        if (entry['coverage'], entry['sparsity'], entry['alpha'], entry['beta'], entry['max_len']) == (wp, ws, alpha, beta, maxlen):\n",
    "            run = entry\n",
    "            break\n",
    "    if entry is None:\n",
    "        raise ValueError('Entry not found: ' + str((dataset, wp, ws, alpha, beta, maxlen)))\n",
    "\n",
    "    return entry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adversaries\n",
    "\n",
    "The adversary set is comprised of:\n",
    "\n",
    "- Decision Tree (DT)\n",
    "- Pruned Decision Tree (DT)\n",
    "- CPAR\n",
    "- FOIL\n",
    "- Trepan\n",
    "- CORELS\n",
    "- SBRL (Scalable Bayesian Rule Lists)\n",
    "\n",
    "Validation files **have already been computed**, they are in `./{$dataset}-validation.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "adversaries = ['corels', 'cpar', 'sbrl']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results_per_bb = {}\n",
    "black_boxes = 'dnn', 'rf'\n",
    "# Data columns\n",
    "meta_cols = ['dataset', 'black_box', 'scoring', 'k']\n",
    "cols = ['alpha',\n",
    "        'beta',\n",
    "        'gamma',\n",
    "        'max_len',\n",
    "        'scoring-fidelities',\n",
    "        'beta-scoring-fidelity', 'beta-scoring-rule_nr',\n",
    "        'coverage', 'beta-scoring-coverage',\n",
    "        'mean_length', 'std_length',\n",
    "        'mean-beta-scoring-length', 'std-beta-scoring-length',\n",
    "        'mean_prediction', 'std-scoring-prediction',\n",
    "        'rule_reduction-beta-scoring', 'len_reduction-beta-scoring','simplicity-beta-scoring',\n",
    "         'feature_frequency', 'scoring-beta-feature_frequency'\n",
    "       ]\n",
    "\n",
    "# Baseline results\n",
    "for bb in black_boxes:\n",
    "    results = []\n",
    "    for dataset in datasets:\n",
    "        for scoring_foo in ['r2', 'coverage', 'fidelity']:\n",
    "            template = logs_template.format(dataset, bb, scoring_foo)\n",
    "\n",
    "            with open(wd + '../output/' + template, 'r') as log:\n",
    "                dataset_results = json.load(log)\n",
    "\n",
    "            df = pd.concat([pd.DataFrame({k: run['results'][k] for k in cols})\n",
    "                            for run in dataset_results['runs']], axis='rows')\n",
    "            df['k'] = [1 for _ in range(df.shape[0])]\n",
    "            df['dataset'] = dataset\n",
    "            df['black_box'] = bb\n",
    "            df['scoring'] = scoring_foo\n",
    "            df = df[meta_cols + cols]\n",
    "            results += [df]\n",
    "\n",
    "    # Full DataFrame construction (Warning, may be slow)\n",
    "    results = pd.concat(results, axis='rows', ignore_index=True)\n",
    "    results_per_bb[bb] = results\n",
    "\n",
    "full_results = pd.concat(list(results_per_bb.values()), axis='rows').drop_duplicates()\n",
    "full_results = full_results.sort_values(['dataset', 'black_box', 'beta'])\n",
    "\n",
    "\n",
    "# Adversaries\n",
    "missing = []\n",
    "results_per_bb = {}\n",
    "for bb in ['rf', 'dnn']:\n",
    "    results = []\n",
    "    for adversary in adversaries:\n",
    "        for dataset in datasets:\n",
    "            for scoring_foo in ['r2', 'coverage', 'fidelity']:\n",
    "                try:\n",
    "                    if dataset == 'german' and adversary == 'corels':\n",
    "                        continue\n",
    "\n",
    "                    template = adversary_logs_template.format(dataset, adversary, bb, scoring_foo)\n",
    "\n",
    "                    with open(wd + '../output/' + template, 'r') as log:\n",
    "                        dataset_results = json.load(log)\n",
    "\n",
    "                    df = pd.concat([pd.DataFrame({k: run['results'][k] for k in cols})\n",
    "                                    for run in dataset_results['runs']], axis='rows')\n",
    "                    df['k'] = [1 for _ in range(df.shape[0])]\n",
    "                    df['dataset'] = dataset\n",
    "                    df['black_box'] = bb\n",
    "                    df['scoring'] = scoring_foo\n",
    "                    df['algorithm'] = adversary\n",
    "                    df = df[meta_cols + ['algorithm'] + cols]\n",
    "                    results += [df]\n",
    "                except FileNotFoundError as e:\n",
    "                    missing.append((dataset, adversary, bb, scoring_foo))\n",
    "\n",
    "    # Full DataFrame construction (Warning, may be slow)\n",
    "    results = pd.concat(results, axis='rows', ignore_index=True)\n",
    "    results_per_bb[bb] = results\n",
    "\n",
    "full_adversaries_results = pd.concat(list(results_per_bb.values()), axis='rows').drop_duplicates()\n",
    "full_adversaries_results = full_adversaries_results[full_adversaries_results.alpha != 0]\n",
    "full_adversaries_results = full_adversaries_results.sort_values(['dataset', 'black_box', 'beta'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plotting utils\n",
    "from bokeh.plotting import figure, output_file, show\n",
    "from bokeh.models import ColumnDataSource, LabelSet, Legend, Range1d, ColorBar\n",
    "from bokeh.models import SingleIntervalTicker, LinearAxis, NumeralTickFormatter\n",
    "from bokeh.models.tickers import ContinuousTicker\n",
    "\n",
    "from bokeh.io import output_notebook, output_file\n",
    "from bokeh.io import export_svgs, export_png\n",
    "\n",
    "# Output in the notebook instead of file\n",
    "# output_notebook()\n",
    "\n",
    "# Color palettes\n",
    "from bokeh.palettes import RdYlGn11 as plt\n",
    "from bokeh.transform import linear_cmap\n",
    "\n",
    "RED   = '#F05F54'\n",
    "BLUE  = '#3169A3'\n",
    "BLACK = '#000000'\n",
    "\n",
    "shapes = ['square', 'circle', 'triangle', 'diamond']\n",
    "plt_colors4 = ['#f16a70', '#b1d877', '#4d4d4d', '#8cdcda']\n",
    "plt_colors3 = ['#BE4A2F', '#225E78', '#72AD2B']\n",
    "plt_colors3 = ['#009988', '#004488', '#bb5566', '#000000', '#ddaa33']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "summary_columns = ['mean', 'std', '25%', '50%', '75%', 'min', 'max']\n",
    "prediction_cols = ['mean_prediction', 'std-scoring-prediction']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting functions: Global models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def global_plot_fidelity_on_beta_cut(measure=None, scoring='r2', black_box=None, draw_left_axis_label=True, name=None):\n",
    "    if measure == 'fidelity':\n",
    "        measure_name = 'beta_fidelity_fidelities'\n",
    "    else:\n",
    "        measure_name = 'beta_scoring_fidelity'\n",
    "        \n",
    "    # Data gathering\n",
    "    if isinstance(black_box, str):\n",
    "        df = full_adversaries_results[(full_adversaries_results.black_box == black_box) & (full_results.alpha == .5)]\n",
    "        df = df.groupby(['dataset', 'beta'])[measure_name].describe()[summary_columns]\n",
    "    else:\n",
    "        df = full_adversaries_results[(full_adversaries_results.black_box.isin(black_box)) & (full_results.alpha == .5)]\n",
    "        df = df.groupby(['dataset', 'beta'])[measure_name].describe()[summary_columns]\n",
    "\n",
    "    # Plot\n",
    "    p = figure(title='Mean fidelity, free β', x_axis_type='linear', x_minor_ticks=5, plot_width=900, plot_height=600)\n",
    "    p.title.text_font_size = '20pt'\n",
    "\n",
    "    # Axes\n",
    "    p.xaxis[0].ticker.desired_num_ticks = 10\n",
    "    p.yaxis[0].ticker.desired_num_ticks = 5\n",
    "    p.xaxis[0].axis_label_text_font_size = '20pt'\n",
    "    p.yaxis[0].axis_label_text_font_size = '20pt'\n",
    "    p.xaxis[0].major_label_text_font_size = '20pt'\n",
    "    p.yaxis[0].major_label_text_font_size = '20pt'\n",
    "    p.xaxis.axis_label = 'β'\n",
    "    p.yaxis.axis_label = 'fidelity'\n",
    "\n",
    "    # Plot borders\n",
    "    left, right, bottom, top = 0, 104, .75, 1.09\n",
    "    p.x_range = Range1d(left, right)\n",
    "    p.y_range = Range1d(bottom, top)\n",
    "\n",
    "    for d, shape, color in zip(datasets, shapes, plt_colors4):\n",
    "        dataset_df = df.loc[d]\n",
    "        \n",
    "        # Fill nan data\n",
    "        nan_index_start = np.argwhere(~dataset_df['mean'].notnull()).flatten().squeeze()\n",
    "        nan_index_start = nan_index_start.item(0) if nan_index_start.size > 0 else dataset_df.shape[0]\n",
    "        dataset_df.loc[~dataset_df['mean'].notnull(), 'mean'] = dataset_df[dataset_df['mean'].notnull()].iloc[-1]['mean']\n",
    "        \n",
    "        x, y = dataset_df.index.values.tolist(), dataset_df['mean'].values\n",
    "        argmax_y = np.where(y == y.max())[0][-1]\n",
    "\n",
    "        # Data labels\n",
    "        source = ColumnDataSource(data=dict(x=x, y=y, names=[str(y_)[:4] for y_ in y]))\n",
    "        computed_source = ColumnDataSource(data=dict(x=x, y=y))\n",
    "        best_source = ColumnDataSource(data=dict(x=[x[argmax_y]], y=[y[argmax_y]]))\n",
    "\n",
    "        # Available data\n",
    "        line = p.line(x='x', y='y', line_width=4, alpha=.5,\n",
    "                      line_color=color, source=computed_source, line_dash='dashed')\n",
    "        dots = getattr(p, shape)(x='x', y='y', size=16, line_width=2, color=color,\n",
    "                                 source=computed_source, legend=d)\n",
    "    # Legend\n",
    "    p.legend.location = 'top_left'\n",
    "    p.legend[0].orientation = 'horizontal'\n",
    "    p.legend.label_text_font_size = '20pt'\n",
    "\n",
    "    if name is None:\n",
    "        show(p)\n",
    "    else:\n",
    "        p.output_backend = 'svg'\n",
    "        export_svgs(p, name)\n",
    "        return p\n",
    "\n",
    "\n",
    "def global_plot_coverage_on_beta_cut(measure=None, black_box=None, draw_left_axis_label=True, name=None, legend_position='bottom_left', legend_orientation='vertical'):\n",
    "    if measure == 'fidelity':\n",
    "        measure_name = 'beta-fidelity-coverage'\n",
    "    else:\n",
    "        measure_name = 'beta-scoring-coverage'\n",
    "        \n",
    "    # Data gathering\n",
    "    if isinstance(black_box, str):\n",
    "        df = full_adversaries_results[(full_adversaries_results.black_box == black_box) & (full_results.alpha == .5)]\n",
    "        df = df.groupby(['dataset', 'beta'])[measure_name].describe()[summary_columns]\n",
    "    else:\n",
    "        df = full_adversaries_results[(full_adversaries_results.black_box.isin(black_box)) & (full_results.alpha == .5)]\n",
    "        df = df.groupby(['dataset', 'beta'])[measure_name].describe()[summary_columns]\n",
    "\n",
    "    # Plot\n",
    "    p = figure(title='Mean coverage, free β', x_axis_type='linear', x_minor_ticks=5, plot_width=900, plot_height=600)\n",
    "    p.title.text_font_size = '20pt'\n",
    "\n",
    "    # Axes\n",
    "    p.xaxis[0].ticker.desired_num_ticks = 10\n",
    "    p.yaxis[0].ticker.desired_num_ticks = 5\n",
    "    p.xaxis[0].axis_label_text_font_size = '20pt'\n",
    "    p.yaxis[0].axis_label_text_font_size = '20pt'\n",
    "    p.xaxis[0].major_label_text_font_size = '20pt'\n",
    "    p.yaxis[0].major_label_text_font_size = '20pt'\n",
    "    p.xaxis.axis_label = 'β'\n",
    "    p.yaxis.axis_label = 'coverage'\n",
    "\n",
    "    # Plot borders\n",
    "    left, right, bottom, top = 0, 109, 0, 1.09\n",
    "    p.x_range = Range1d(left, right)\n",
    "    p.y_range = Range1d(bottom, top)\n",
    "\n",
    "    for d, shape, color in zip(datasets, shapes, plt_colors4):\n",
    "        dataset_df = df.loc[d]\n",
    "        \n",
    "        # Fill nan data\n",
    "        nan_index_start = np.argwhere(~dataset_df['mean'].notnull()).flatten().squeeze()\n",
    "        nan_index_start = nan_index_start.item(0) if nan_index_start.size > 0 else dataset_df.shape[0]\n",
    "        dataset_df.loc[~dataset_df['mean'].notnull(), 'mean'] = dataset_df[dataset_df['mean'].notnull()].iloc[-1]['mean']\n",
    "        \n",
    "        x, y = dataset_df.index.values.tolist(), dataset_df['mean'].values\n",
    "        argmax_y = np.where(y == y.max())[0][-1]\n",
    "\n",
    "        # Data labels\n",
    "        source = ColumnDataSource(data=dict(x=x, y=y, names=[str(y_)[:4] for y_ in y]))\n",
    "        computed_source = ColumnDataSource(data=dict(x=x, y=y))\n",
    "        best_source = ColumnDataSource(data=dict(x=[x[argmax_y]], y=[y[argmax_y]]))\n",
    "\n",
    "        # Available data\n",
    "        line = p.line(x='x', y='y', line_width=4, alpha=.5,\n",
    "                      line_color=color, source=computed_source, line_dash='dashed')\n",
    "        dots = getattr(p, shape)(x='x', y='y', size=16, line_width=2, color=color,\n",
    "                                 source=computed_source, legend=d)\n",
    "    # Legend\n",
    "    p.legend.location = legend_position\n",
    "    p.legend[0].orientation = legend_orientation\n",
    "    p.legend.label_text_font_size = '20pt'\n",
    "\n",
    "    if name is None:\n",
    "        show(p)\n",
    "    else:\n",
    "        p.output_backend = 'svg'\n",
    "        export_svgs(p, name)\n",
    "        return p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting functions: Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_fidelity_on_beta_cut(scoring='r2', black_box=None, draw_left_axis_label=True, name=None):    \n",
    "    # Data gathering\n",
    "    if isinstance(black_box, str):\n",
    "        df = full_results[(full_results.black_box == black_box) & (full_results.scoring == scoring)\\\n",
    "                         & (full_results.alpha == .5)]\n",
    "    else:\n",
    "        df = full_results[(full_results.black_box.isin(black_box)) & (full_results.scoring == scoring)\\\n",
    "                         & (full_results.alpha == .5)]\n",
    "\n",
    "    # Plot\n",
    "    scoring = 'r²' if scoring == 'r2' else scoring\n",
    "    p = figure(title='[' + scoring + '] Fidelity [' + black_box.upper() + ']', x_axis_type='linear',\n",
    "               x_minor_ticks=5, plot_width=600, plot_height=500)\n",
    "    p.title.text_font_size = '20pt'\n",
    "\n",
    "    # Axes\n",
    "    p.xaxis[0].ticker.desired_num_ticks = 10\n",
    "    p.yaxis[0].ticker.desired_num_ticks = 5\n",
    "    p.xaxis[0].axis_label_text_font_size = '25pt'\n",
    "    p.yaxis[0].axis_label_text_font_size = '25pt' if draw_left_axis_label else '0pt'\n",
    "    p.xaxis[0].major_label_text_font_size = '20pt'\n",
    "    p.yaxis[0].major_label_text_font_size = '20pt' if draw_left_axis_label else '0pt'\n",
    "    p.xaxis.axis_label = 'β'\n",
    "    # p.yaxis.visible = draw_left_axis_label\n",
    "    p.yaxis.axis_label = 'fidelity' if draw_left_axis_label else ''\n",
    "\n",
    "    # Plot borders\n",
    "    left, right, bottom, top = 0, 104, .5, 1.09\n",
    "    p.x_range = Range1d(left, right)\n",
    "    p.y_range = Range1d(bottom, top)\n",
    "\n",
    "    for d, shape, color in zip(datasets, shapes, plt_colors4):\n",
    "        dataset_df = df[df.dataset == d]\n",
    "        \n",
    "        # Fill nan data\n",
    "        nan_index_start = np.argwhere(~dataset_df['beta-scoring-fidelity'].notnull()).flatten().squeeze()\n",
    "        nan_index_start = nan_index_start.item(0) if nan_index_start.size > 0 else dataset_df.shape[0]\n",
    "        dataset_df.loc[~dataset_df['beta-scoring-fidelity'].notnull(), 'beta-scoring-fidelity'] = dataset_df[dataset_df['beta-scoring-fidelity'].notnull()].iloc[-1]['beta-scoring-fidelity']\n",
    "        \n",
    "        x, y = dataset_df.beta.values, dataset_df['beta-scoring-fidelity'].values\n",
    "        argmax_y = np.where(y == y.max())[0][-1]\n",
    "\n",
    "        # Data labels\n",
    "        source = ColumnDataSource(data=dict(x=x, y=y, names=[str(y_)[:4] for y_ in y]))\n",
    "        computed_source = ColumnDataSource(data=dict(x=x, y=y))\n",
    "        best_source = ColumnDataSource(data=dict(x=[x[argmax_y]], y=[y[argmax_y]]))\n",
    "\n",
    "        # Available data\n",
    "        line = p.line(x='x', y='y', line_width=4, alpha=.5,\n",
    "                      line_color=color, source=computed_source, line_dash='dashed')\n",
    "        dots = getattr(p, shape)(x='x', y='y', size=16, line_width=2, color=color,\n",
    "                                 source=computed_source, legend=d)\n",
    "    # Legend\n",
    "    p.legend.location = 'bottom_left'\n",
    "    p.legend[0].orientation = 'horizontal'\n",
    "    p.legend.label_text_font_size = '20pt'\n",
    "\n",
    "    if name is None:\n",
    "        show(p)\n",
    "    else:\n",
    "        p.output_backend = 'svg'\n",
    "        export_svgs(p, name)\n",
    "        return p\n",
    "\n",
    "\n",
    "def plot_coverage_on_beta_cut(scoring='r2', black_box=None, draw_left_axis_label=True, draw_bottom_axis=True, name=None, legend_position='bottom_left', legend_orientation='vertical'):\n",
    "    # Data gathering\n",
    "    if isinstance(black_box, str):\n",
    "        df = full_results[(full_results.black_box == black_box) & (full_results.scoring == scoring)\\\n",
    "                         & (full_results.alpha == .5)]\n",
    "    else:\n",
    "        df = full_results[(full_results.black_box.isin(black_box)) & (full_results.scoring == scoring)\\\n",
    "                         & (full_results.alpha == .5)]\n",
    "\n",
    "    # Plot\n",
    "    scoring = 'r²' if scoring == 'r2' else scoring\n",
    "    p = figure(title='[' + scoring + '] Coverage [' + black_box.upper() + ']',\n",
    "               x_axis_type='linear', x_minor_ticks=5, plot_width=600, plot_height=500)\n",
    "    p.title.text_font_size = '20pt'\n",
    "\n",
    "    # Axes\n",
    "    p.xaxis[0].ticker.desired_num_ticks = 10\n",
    "    p.yaxis[0].ticker.desired_num_ticks = 5\n",
    "    p.xaxis[0].axis_label_text_font_size = '25pt'\n",
    "    p.yaxis[0].axis_label_text_font_size = '25pt' if draw_left_axis_label else '0pt'\n",
    "    p.xaxis[0].major_label_text_font_size = '20pt'\n",
    "    p.yaxis[0].major_label_text_font_size = '20pt' if draw_left_axis_label else '0pt'\n",
    "    p.xaxis.axis_label = 'β'\n",
    "    # p.yaxis.visible = draw_left_axis_label\n",
    "    p.yaxis.axis_label = 'coverage' if draw_left_axis_label else ''\n",
    "\n",
    "    # Plot borders\n",
    "    left, right, bottom, top = 0, 109, 0, 1.09\n",
    "    p.x_range = Range1d(left, right)\n",
    "    p.y_range = Range1d(bottom, top)\n",
    "\n",
    "    for d, shape, color in zip(datasets, shapes, plt_colors4):\n",
    "        dataset_df = df[df.dataset == d]\n",
    "        \n",
    "        # Fill nan data\n",
    "        nan_index_start = np.argwhere(~dataset_df['beta-scoring-coverage'].notnull()).flatten().squeeze()\n",
    "        nan_index_start = nan_index_start.item(0) if nan_index_start.size > 0 else dataset_df.shape[0]\n",
    "        dataset_df.loc[~dataset_df['beta-scoring-coverage'].notnull(), 'beta-scoring-coverage'] = dataset_df[dataset_df['beta-scoring-coverage'].notnull()].iloc[-1]['beta-scoring-coverage']\n",
    "        \n",
    "        x, y = dataset_df.beta.values, dataset_df['beta-scoring-coverage'].values\n",
    "        argmax_y = np.where(y == y.max())[0][-1]\n",
    "\n",
    "        # Data labels\n",
    "        source = ColumnDataSource(data=dict(x=x, y=y, names=[str(y_)[:4] for y_ in y]))\n",
    "        computed_source = ColumnDataSource(data=dict(x=x, y=y))\n",
    "        best_source = ColumnDataSource(data=dict(x=[x[argmax_y]], y=[y[argmax_y]]))\n",
    "\n",
    "        # Available data\n",
    "        line = p.line(x='x', y='y', line_width=4, alpha=.5,\n",
    "                      line_color=color, source=computed_source, line_dash='dashed')\n",
    "        dots = getattr(p, shape)(x='x', y='y', size=16, line_width=2, color=color,\n",
    "                                 source=computed_source, legend=d)\n",
    "    # Legend\n",
    "    p.legend.location = legend_position\n",
    "    p.legend[0].orientation = legend_orientation\n",
    "    p.legend.label_text_font_size = '20pt'\n",
    "\n",
    "    if name is None:\n",
    "        show(p)\n",
    "    else:\n",
    "        p.output_backend = 'svg'\n",
    "        export_svgs(p, name)\n",
    "        return p\n",
    "\n",
    "\n",
    "def plot_scorings_on_beta_cut(dataset, black_box, measure='fidelity', draw_left_axis_label=True, draw_bottom_axis=True, name=None, legend_position='bottom_left', legend_orientation='vertical'):\n",
    "    # Data gathering\n",
    "    if isinstance(black_box, str):\n",
    "        df = full_results[(full_results.black_box == black_box) & (full_results.dataset == dataset)\\\n",
    "                         & (full_results.alpha == .5)]\n",
    "        df = df.drop_duplicates()\n",
    "    x = sorted(set(df.beta))\n",
    "\n",
    "    # Plot\n",
    "    p = figure(title='[' + dataset.capitalize() + '] [' + black_box.upper() + ']',\n",
    "               x_axis_type='linear', x_minor_ticks=5, plot_width=600, plot_height=500)\n",
    "    p.title.text_font_size = '20pt'\n",
    "\n",
    "    # Axes\n",
    "    p.xaxis[0].ticker.desired_num_ticks = 10\n",
    "    p.yaxis[0].ticker.desired_num_ticks = 5\n",
    "    p.xaxis[0].axis_label_text_font_size = '25pt'\n",
    "    p.yaxis[0].axis_label_text_font_size = '25pt' if draw_left_axis_label else '0pt'\n",
    "    p.xaxis[0].major_label_text_font_size = '20pt' if draw_bottom_axis else '0pt'\n",
    "    p.yaxis[0].major_label_text_font_size = '20pt' if draw_left_axis_label else '0pt'\n",
    "    p.xaxis.axis_label = 'β' if draw_bottom_axis else ''\n",
    "    p.yaxis.axis_label = measure if draw_left_axis_label else ''\n",
    "\n",
    "    # Plot borders\n",
    "    left, right, bottom, top = 0, 109, 0, 1.09\n",
    "    p.x_range = Range1d(left, right)\n",
    "    p.y_range = Range1d(bottom, top)\n",
    "\n",
    "    for candidate_measure, shape, color in zip(('fidelity', 'r2', 'coverage'), shapes, plt_colors3):\n",
    "        data_df = df[df.scoring == candidate_measure]\n",
    "        candidate_measure = 'r²' if candidate_measure == 'r2' else candidate_measure\n",
    "        x = data_df['beta'].values\n",
    "        y = data_df['beta-scoring-' + measure].values\n",
    "            \n",
    "        # x, y = data_df.index.values.tolist(), data_df['mean'].values\n",
    "        if np.isnan(y).any():\n",
    "            nan_index = np.argwhere(np.isnan(y)).squeeze().item(0)\n",
    "            x, y = x[:nan_index], y[:nan_index]\n",
    "            x = x[:y.shape[0]]\n",
    "        argmax_y = np.where(y == y.max())[0][-1]\n",
    "        \n",
    "        # Data labels\n",
    "        source = ColumnDataSource(data=dict(x=x, y=y, names=[str(y_)[:4] for y_ in y]))\n",
    "        computed_source = ColumnDataSource(data=dict(x=x, y=y))\n",
    "        best_source = ColumnDataSource(data=dict(x=[x[argmax_y]], y=[y[argmax_y]]))\n",
    "\n",
    "        # Available data\n",
    "        line = p.line(x='x', y='y', line_width=4, alpha=.5,\n",
    "                      line_color=color, source=computed_source, line_dash='dashed')\n",
    "        dots = getattr(p, shape)(x='x', y='y', size=16, line_width=2, color=color,\n",
    "                                 source=computed_source, legend=candidate_measure[:3])\n",
    "        dots = getattr(p, shape)(x='x', y='y', size=32, line_width=2, color=color, fill_alpha=0,\n",
    "                                 source=best_source, legend=candidate_measure[:3])\n",
    "    \n",
    "    # Draw union baseline, i.e. cut on beta = 0\n",
    "    df_prime = full_results[(full_results.black_box == black_box) & (full_results.dataset == dataset)\n",
    "                            & (full_results.scoring == 'r2') & (full_results.beta == 0)]\n",
    "    base_y = df_prime['scoring-fidelities'].values.item(0)\n",
    "    # p.line(x=[left, right], y=[base_y, base_y], line_width=2, color=BLACK, alpha=.5, line_dash='dashed', legend='no pruning')\n",
    "    \n",
    "    # Legend\n",
    "    p.legend.location = legend_position\n",
    "    p.legend[0].orientation = legend_orientation\n",
    "    p.legend.label_text_font_size = '20pt'\n",
    "\n",
    "    if name is None:\n",
    "        show(p)\n",
    "    else:\n",
    "        p.output_backend = 'svg'\n",
    "        export_svgs(p, name)\n",
    "        return p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adult dnn fidelity\n",
      "adult dnn coverage\n",
      "adult rf fidelity\n",
      "adult rf coverage\n",
      "churn dnn fidelity\n",
      "churn dnn coverage\n",
      "churn rf fidelity\n",
      "churn rf coverage\n",
      "compas dnn fidelity\n",
      "compas dnn coverage\n",
      "compas rf fidelity\n",
      "compas rf coverage\n",
      "german dnn fidelity\n",
      "german dnn coverage\n",
      "german rf fidelity\n",
      "german rf coverage\n"
     ]
    }
   ],
   "source": [
    "for d in datasets:\n",
    "    bottom = d == 'german'\n",
    "    for bb in ['dnn', 'rf']:\n",
    "        for measure in ['fidelity', 'coverage']:\n",
    "            left_axis = measure == 'fidelity'\n",
    "            print(d, bb, measure)\n",
    "            plot_scorings_on_beta_cut(d, bb, measure=measure,\n",
    "                                      draw_left_axis_label=left_axis, draw_bottom_axis=bottom,\n",
    "                                      name=None, legend_position='bottom_left', legend_orientation='horizontal')\n",
    "\n",
    "# Black box by black_box\n",
    "for bb in black_boxes:\n",
    "    for cut in ['beta']:\n",
    "        for scoring, left_axis in [('r2', True), ('coverage', False), ('fidelity', False)]:\n",
    "            continue\n",
    "            plot_fidelity_on_beta_cut(black_box=bb, scoring=scoring, name=None, draw_left_axis_label=left_axis)\n",
    "            \n",
    "for bb in black_boxes:\n",
    "    for cut in ['beta']:\n",
    "        for measure, scoring, left_axis in [('scoring', 'r2', True), ('coverage', 'coverage', False), ('fidelity', 'fidelity', False)]:            \n",
    "            continue\n",
    "            plot_coverage_on_beta_cut(black_box=bb, scoring=scoring, name=None, draw_left_axis_label=left_axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "checkpoint('analysis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adversaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_fidelity_on_beta_cut_adversaries(scoring='r2', black_box=None, draw_left_axis_label=True, name=None):    \n",
    "    # Data gathering\n",
    "    if isinstance(black_box, str):\n",
    "        df = full_adversaries_results[(full_adversaries_results.black_box == black_box) & (full_adversaries_results.scoring == scoring)\\\n",
    "                         & (full_adversaries_results.alpha == .5)]\n",
    "    else:\n",
    "        df = full_adversaries_results[(full_adversaries_results.black_box.isin(black_box)) & (full_adversaries_results.scoring == scoring)\\\n",
    "                         & (full_adversaries_results.alpha == .5)]\n",
    "\n",
    "    # Plot\n",
    "    scoring = 'r²' if scoring == 'r2' else scoring\n",
    "    p = figure(title='[' + scoring + '] Fidelity [' + black_box.upper() + ']', x_axis_type='linear',\n",
    "               x_minor_ticks=5, plot_width=600, plot_height=500)\n",
    "    p.title.text_font_size = '20pt'\n",
    "\n",
    "    # Axes\n",
    "    p.xaxis[0].ticker.desired_num_ticks = 10\n",
    "    p.yaxis[0].ticker.desired_num_ticks = 5\n",
    "    p.xaxis[0].axis_label_text_font_size = '25pt'\n",
    "    p.yaxis[0].axis_label_text_font_size = '25pt' if draw_left_axis_label else '0pt'\n",
    "    p.xaxis[0].major_label_text_font_size = '20pt'\n",
    "    p.yaxis[0].major_label_text_font_size = '20pt' if draw_left_axis_label else '0pt'\n",
    "    p.xaxis.axis_label = 'β'\n",
    "    # p.yaxis.visible = draw_left_axis_label\n",
    "    p.yaxis.axis_label = 'fidelity' if draw_left_axis_label else ''\n",
    "\n",
    "    # Plot borders\n",
    "    left, right, bottom, top = 0, 104, .5, 1.09\n",
    "    p.x_range = Range1d(left, right)\n",
    "    p.y_range = Range1d(bottom, top)\n",
    "\n",
    "    for d, shape, color in zip(datasets, shapes, plt_colors4):\n",
    "        dataset_df = df[df.dataset == d]\n",
    "        \n",
    "        # Fill nan data\n",
    "        nan_index_start = np.argwhere(~dataset_df['beta-scoring-fidelity'].notnull()).flatten().squeeze()\n",
    "        nan_index_start = nan_index_start.item(0) if nan_index_start.size > 0 else dataset_df.shape[0]\n",
    "        dataset_df.loc[~dataset_df['beta-scoring-fidelity'].notnull(), 'beta-scoring-fidelity'] = dataset_df[dataset_df['beta-scoring-fidelity'].notnull()].iloc[-1]['beta-scoring-fidelity']\n",
    "        \n",
    "        x, y = dataset_df.beta.values, dataset_df['beta-scoring-fidelity'].values\n",
    "        argmax_y = np.where(y == y.max())[0][-1]\n",
    "\n",
    "        # Data labels\n",
    "        source = ColumnDataSource(data=dict(x=x, y=y, names=[str(y_)[:4] for y_ in y]))\n",
    "        computed_source = ColumnDataSource(data=dict(x=x, y=y))\n",
    "        best_source = ColumnDataSource(data=dict(x=[x[argmax_y]], y=[y[argmax_y]]))\n",
    "\n",
    "        # Available data\n",
    "        line = p.line(x='x', y='y', line_width=4, alpha=.5,\n",
    "                      line_color=color, source=computed_source, line_dash='dashed')\n",
    "        dots = getattr(p, shape)(x='x', y='y', size=16, line_width=2, color=color,\n",
    "                                 source=computed_source, legend=d)\n",
    "    # Legend\n",
    "    p.legend.location = 'bottom_left'\n",
    "    p.legend[0].orientation = 'horizontal'\n",
    "    p.legend.label_text_font_size = '20pt'\n",
    "\n",
    "    if name is None:\n",
    "        show(p)\n",
    "    else:\n",
    "        p.output_backend = 'svg'\n",
    "        export_svgs(p, name)\n",
    "        return p\n",
    "\n",
    "\n",
    "def plot_coverage_on_beta_cut_adversaries(scoring='r2', black_box=None, draw_left_axis_label=True, draw_bottom_axis=True, name=None, legend_position='bottom_left', legend_orientation='vertical'):\n",
    "    # Data gathering\n",
    "    if isinstance(black_box, str):\n",
    "        df = full_adversaries_results[(full_adversaries_results.black_box == black_box) & (full_adversaries_results.scoring == scoring)\\\n",
    "                         & (full_adversaries_results.alpha == .5)]\n",
    "    else:\n",
    "        df = full_adversaries_results[(full_adversaries_results.black_box.isin(black_box)) & (full_adversaries_results.scoring == scoring)\\\n",
    "                         & (full_adversaries_results.alpha == .5)]\n",
    "\n",
    "    # Plot\n",
    "    scoring = 'r²' if scoring == 'r2' else scoring\n",
    "    p = figure(title='[' + scoring + '] Coverage [' + black_box.upper() + ']',\n",
    "               x_axis_type='linear', x_minor_ticks=5, plot_width=600, plot_height=500)\n",
    "    p.title.text_font_size = '20pt'\n",
    "\n",
    "    # Axes\n",
    "    p.xaxis[0].ticker.desired_num_ticks = 10\n",
    "    p.yaxis[0].ticker.desired_num_ticks = 5\n",
    "    p.xaxis[0].axis_label_text_font_size = '25pt'\n",
    "    p.yaxis[0].axis_label_text_font_size = '25pt' if draw_left_axis_label else '0pt'\n",
    "    p.xaxis[0].major_label_text_font_size = '20pt'\n",
    "    p.yaxis[0].major_label_text_font_size = '20pt' if draw_left_axis_label else '0pt'\n",
    "    p.xaxis.axis_label = 'β'\n",
    "    # p.yaxis.visible = draw_left_axis_label\n",
    "    p.yaxis.axis_label = 'coverage' if draw_left_axis_label else ''\n",
    "\n",
    "    # Plot borders\n",
    "    left, right, bottom, top = 0, 109, 0, 1.09\n",
    "    p.x_range = Range1d(left, right)\n",
    "    p.y_range = Range1d(bottom, top)\n",
    "\n",
    "    for d, shape, color in zip(datasets, shapes, plt_colors4):\n",
    "        dataset_df = df[df.dataset == d]\n",
    "        \n",
    "        # Fill nan data\n",
    "        nan_index_start = np.argwhere(~dataset_df['beta-scoring-coverage'].notnull()).flatten().squeeze()\n",
    "        nan_index_start = nan_index_start.item(0) if nan_index_start.size > 0 else dataset_df.shape[0]\n",
    "        dataset_df.loc[~dataset_df['beta-scoring-coverage'].notnull(), 'beta-scoring-coverage'] = dataset_df[dataset_df['beta-scoring-coverage'].notnull()].iloc[-1]['beta-scoring-coverage']\n",
    "        \n",
    "        x, y = dataset_df.beta.values, dataset_df['beta-scoring-coverage'].values\n",
    "        argmax_y = np.where(y == y.max())[0][-1]\n",
    "\n",
    "        # Data labels\n",
    "        source = ColumnDataSource(data=dict(x=x, y=y, names=[str(y_)[:4] for y_ in y]))\n",
    "        computed_source = ColumnDataSource(data=dict(x=x, y=y))\n",
    "        best_source = ColumnDataSource(data=dict(x=[x[argmax_y]], y=[y[argmax_y]]))\n",
    "\n",
    "        # Available data\n",
    "        line = p.line(x='x', y='y', line_width=4, alpha=.5,\n",
    "                      line_color=color, source=computed_source, line_dash='dashed')\n",
    "        dots = getattr(p, shape)(x='x', y='y', size=16, line_width=2, color=color,\n",
    "                                 source=computed_source, legend=d)\n",
    "    # Legend\n",
    "    p.legend.location = legend_position\n",
    "    p.legend[0].orientation = legend_orientation\n",
    "    p.legend.label_text_font_size = '20pt'\n",
    "\n",
    "    if name is None:\n",
    "        show(p)\n",
    "    else:\n",
    "        p.output_backend = 'svg'\n",
    "        export_svgs(p, name)\n",
    "        return p\n",
    "\n",
    "\n",
    "def plot_scorings_on_beta_cut_adversaries(dataset, black_box, measure='fidelity', draw_left_axis_label=True, name=None, legend_position='bottom_left', legend_orientation='vertical'):\n",
    "    # Data gathering\n",
    "    if isinstance(black_box, str):\n",
    "        df = full_adversaries_results[(full_adversaries_results.black_box == black_box) & (full_adversaries_results.dataset == dataset)\\\n",
    "                         & (full_adversaries_results.alpha == .5)]\n",
    "        df = df.drop_duplicates()\n",
    "    x = sorted(set(df.beta))\n",
    "\n",
    "    # Plot\n",
    "    p = figure(title='[' + dataset.capitalize() + '] [' + black_box.upper() + ']',\n",
    "               x_axis_type='linear', x_minor_ticks=5, plot_width=600, plot_height=500)\n",
    "    p.title.text_font_size = '20pt'\n",
    "\n",
    "    # Axes\n",
    "    p.xaxis[0].ticker.desired_num_ticks = 10\n",
    "    p.yaxis[0].ticker.desired_num_ticks = 5\n",
    "    p.xaxis[0].axis_label_text_font_size = '25pt'\n",
    "    p.yaxis[0].axis_label_text_font_size = '25pt' if draw_left_axis_label else '0pt'\n",
    "    p.xaxis[0].major_label_text_font_size = '20pt'\n",
    "    p.yaxis[0].major_label_text_font_size = '20pt' if draw_left_axis_label else '0pt'\n",
    "    p.xaxis.axis_label = 'β'\n",
    "    p.yaxis.axis_label = measure\n",
    "\n",
    "    # Plot borders\n",
    "    left, right, bottom, top = 0, 109, .5, 1.09\n",
    "    p.x_range = Range1d(left, right)\n",
    "    p.y_range = Range1d(bottom, top)\n",
    "\n",
    "    for candidate_measure, shape, color in zip(('fidelity', 'r2', 'coverage'), shapes, plt_colors3):\n",
    "        data_df = df[df.scoring == candidate_measure]\n",
    "        candidate_measure = 'r²' if candidate_measure == 'r2' else candidate_measure\n",
    "        x = data_df['beta'].values\n",
    "        y = data_df['beta-scoring-fidelity'].values\n",
    "            \n",
    "        # x, y = data_df.index.values.tolist(), data_df['mean'].values\n",
    "        if np.isnan(y).any():\n",
    "            nan_index = np.argwhere(np.isnan(y)).squeeze().item(0)\n",
    "            x, y = x[:nan_index], y[:nan_index]\n",
    "            x = x[:y.shape[0]]\n",
    "        argmax_y = np.where(y == y.max())[0][-1]\n",
    "        \n",
    "        # Data labels\n",
    "        source = ColumnDataSource(data=dict(x=x, y=y, names=[str(y_)[:4] for y_ in y]))\n",
    "        computed_source = ColumnDataSource(data=dict(x=x, y=y))\n",
    "        best_source = ColumnDataSource(data=dict(x=[x[argmax_y]], y=[y[argmax_y]]))\n",
    "\n",
    "        # Available data\n",
    "        line = p.line(x='x', y='y', line_width=4, alpha=.5,\n",
    "                      line_color=color, source=computed_source, line_dash='dashed')\n",
    "        dots = getattr(p, shape)(x='x', y='y', size=16, line_width=2, color=color,\n",
    "                                 source=computed_source, legend=candidate_measure[:3])\n",
    "        dots = getattr(p, shape)(x='x', y='y', size=32, line_width=2, color=color, fill_alpha=0,\n",
    "                                 source=best_source, legend=candidate_measure[:3])\n",
    "    \n",
    "    # Draw union baseline, i.e. cut on beta = 0\n",
    "    df_prime = full_adversaries_results[(full_adversaries_results.black_box == black_box) & (full_adversaries_results.dataset == dataset)\n",
    "                            & (full_adversaries_results.scoring == 'r2') & (full_adversaries_results.beta == 0)]\n",
    "    base_y = df_prime['scoring-fidelities'].values.item(0)\n",
    "    p.line(x=[left, right], y=[base_y, base_y], line_width=2, color=BLACK, alpha=.5, line_dash='dashed',\n",
    "           legend='no pruning')    \n",
    "    \n",
    "    # Legend\n",
    "    p.legend.location = legend_position\n",
    "    p.legend[0].orientation = legend_orientation\n",
    "    p.legend.label_text_font_size = '20pt'\n",
    "\n",
    "    if name is None:\n",
    "        show(p)\n",
    "    else:\n",
    "        p.output_backend = 'svg'\n",
    "        export_svgs(p, name)\n",
    "        return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top\n",
      "1800.25\n",
      "rule_nr\n",
      "adult dnn corels\n",
      "adult dnn [1 1 1 1 1 1]\n",
      "adult dnn cpar\n",
      "adult dnn [299 224 150  75  30   3]\n",
      "adult dnn sbrl\n",
      "adult dnn [24 18 12  6  3  1]\n",
      "adult dnn r2\n",
      "adult dnn [1324  993  662  331  133   14]\n",
      "top\n",
      "275.25\n",
      "rule_nr\n",
      "churn dnn corels\n",
      "churn dnn [3 2 2 1 1 1]\n",
      "churn dnn cpar\n",
      "churn dnn [94 71 48 24 12  2]\n",
      "churn dnn sbrl\n",
      "churn dnn [6 4 3 2 1 1]\n",
      "churn dnn r2\n",
      "churn dnn [201 151 101  51  21   4]\n",
      "top\n",
      "2807.75\n",
      "rule_nr\n",
      "compas dnn corels\n",
      "compas dnn [1 1 1 1 1 1]\n",
      "compas dnn cpar\n",
      "compas dnn [2247 1686 1124  562  227   72]\n",
      "compas dnn sbrl\n",
      "compas dnn [7 7 7 2 1 1]\n",
      "compas dnn r2\n",
      "compas dnn [232 174 116  58  24   3]\n",
      "top\n",
      "146.5\n",
      "rule_nr\n",
      "german dnn cpar\n",
      "german dnn [26 19 13  7  3  1]\n",
      "german dnn sbrl\n",
      "german dnn [2 2 2 2 2 2]\n",
      "german dnn r2\n",
      "german dnn [84 63 42 21  9  1]\n",
      "top\n",
      "1800.25\n",
      "rule_nr\n",
      "adult rf corels\n",
      "adult rf [1 1 1 1 1 1]\n",
      "adult rf cpar\n",
      "adult rf [85 64 43 22  9  1]\n",
      "adult rf sbrl\n",
      "adult rf [26 20 13  7  3  1]\n",
      "adult rf r2\n",
      "adult rf [1441 1081  721  361  146   17]\n",
      "top\n",
      "275.25\n",
      "rule_nr\n",
      "churn rf corels\n",
      "churn rf [1 1 1 1 1 1]\n",
      "churn rf cpar\n",
      "churn rf [130  97  66  35  13   2]\n",
      "churn rf sbrl\n",
      "churn rf [6 6 6 6 1 1]\n",
      "churn rf r2\n",
      "churn rf [221 166 111  56  23   3]\n",
      "top\n",
      "399.0\n",
      "rule_nr\n",
      "compas rf corels\n",
      "compas rf [2 1 1 1 1 1]\n",
      "compas rf cpar\n",
      "compas rf [44 33 22 11  5  1]\n",
      "compas rf sbrl\n",
      "compas rf [5 5 3 2 1 1]\n",
      "compas rf r2\n",
      "compas rf [320 240 160  82  32   5]\n",
      "top\n",
      "146.5\n",
      "rule_nr\n",
      "german rf cpar\n",
      "german rf [18 13  9  5  2  1]\n",
      "german rf sbrl\n",
      "german rf [6 4 3 2 1 1]\n",
      "german rf r2\n",
      "german rf [118  88  59  30  12   2]\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import hmean\n",
    "\n",
    "def hmean_(a, b):\n",
    "    return 0 if a == 0 or b == 0 else hmean([a, b])\n",
    "\n",
    "hmeans = [hmean_(a, b) for a, b in full_adversaries_results[['beta-scoring-fidelity', 'beta-scoring-coverage']].values]\n",
    "full_adversaries_results['beta-scoring-hmean'] = hmeans\n",
    "hmeans = [hmean_(a, b) for a, b in full_results[['beta-scoring-fidelity', 'beta-scoring-coverage']].values]\n",
    "full_results['beta-scoring-hmean'] = hmeans\n",
    "\n",
    "draw_left_axis_label = True\n",
    "legend_position = 'bottom_left'\n",
    "legend_orientation = 'horizontal'\n",
    "name = None\n",
    "\n",
    "plt_colors3 = ['#009988', '#004488', '#ddaa33', '#bb5566', '#000000']\n",
    "for bb in black_boxes:\n",
    "    for dataset in datasets:\n",
    "        top_ = full_adversaries_results[(full_adversaries_results.dataset == dataset)\\\n",
    "                                       & (full_adversaries_results.black_box == bb)]['beta-scoring-rule_nr'].values.max()\n",
    "        top_ = max(top_, full_results[(full_results.scoring == 'r2') & (full_results.dataset == dataset)]['beta-scoring-rule_nr'].values.max())\n",
    "        bottom_ = - (top_ / p.yaxis[0].ticker.desired_num_ticks + 1)\n",
    "        top_ = top_ + (top_ / p.yaxis[0].ticker.desired_num_ticks - 1)\n",
    "        \n",
    "        # Plot borders\n",
    "        left, right, bottom, top = -9, 109, bottom_, top_\n",
    "        print('top')\n",
    "        print(top)\n",
    "        for foo in ['rule_nr']:\n",
    "            draw_left_axis_label = True\n",
    "\n",
    "            # Plot\n",
    "            p = figure(x_axis_type='linear', x_minor_ticks=5, plot_width=600, plot_height=400,\n",
    "                      title=dataset.capitalize() + ' - ' + bb.upper())\n",
    "            p.title.text_font_size = '25pt'\n",
    "\n",
    "            # Axes\n",
    "            p.xaxis[0].ticker.desired_num_ticks = 5\n",
    "            p.yaxis[0].ticker.desired_num_ticks = 4\n",
    "            p.xaxis[0].axis_label_text_font_size = '25pt'\n",
    "            p.yaxis[0].axis_label_text_font_size = '25pt'\n",
    "            p.xaxis[0].major_label_text_font_size = '25pt'\n",
    "            p.yaxis[0].major_label_text_font_size = '25pt'\n",
    "            p.xaxis.axis_label = 'β'\n",
    "            p.yaxis.axis_label = 'size'\n",
    "            p.xaxis.major_tick_line_color = None  # turn off x-axis major ticks\n",
    "            p.xaxis.minor_tick_line_color = None  # turn off x-axis minor ticks\n",
    "            p.yaxis.major_tick_line_color = None  # turn off y-axis major ticks\n",
    "            p.yaxis.minor_tick_line_color = None  # turn off y-axis minor ticks\n",
    "            p.x_range = Range1d(left, right)\n",
    "            p.y_range = Range1d(bottom, top)\n",
    "            \n",
    "            legend_entries = []\n",
    "            \n",
    "            # Draw union baseline, i.e. cut on beta = 0\n",
    "            df_prime = full_adversaries_results[(full_adversaries_results.black_box == bb)\\\n",
    "                                                & (full_adversaries_results.dataset == dataset)\\\n",
    "                                                & (full_adversaries_results.scoring == 'r2')\\\n",
    "                                                & (full_adversaries_results.beta == 0)]\n",
    "            base_y = df_prime['scoring-fidelities'].values.item(0)\n",
    "            # p.line(x=[left, right], y=[base_y, base_y], line_width=2, color=BLACK, alpha=.5, line_dash='dashed', legend='no pruning')\n",
    "            \n",
    "            print(foo)\n",
    "            for adv, shape, color in zip(adversaries + ['r2'], shapes, plt_colors3):     \n",
    "                if dataset == 'german' and adv == 'corels':\n",
    "                    continue\n",
    "                measure = foo\n",
    "                print(dataset, bb, adv)\n",
    "                x = [0, 25, 50, 75, 90, 99]\n",
    "                if adv != 'r2':\n",
    "                    df = full_adversaries_results[(full_adversaries_results.scoring == 'r2')\\\n",
    "                                                  & (full_adversaries_results.dataset == dataset)\\\n",
    "                                                  & (full_adversaries_results.black_box == bb)\n",
    "                                                 & (full_adversaries_results.algorithm == adv)]\\\n",
    "                                                .groupby(['beta', 'algorithm'])\\\n",
    "                        [['beta-scoring-' + foo]].mean()\n",
    "                    y = [df.loc[b, adv].values.item(0) for b in x]\n",
    "                else:\n",
    "                    df = full_results[(full_results.scoring == 'r2')\\\n",
    "                                      & (full_results.dataset == dataset)]\\\n",
    "                                        .groupby(['beta', 'black_box', 'dataset'])\\\n",
    "                        [['beta-scoring-' + foo]].mean()\n",
    "                    y = [df.loc[b, bb, dataset].values.item(0) for b in x]\n",
    "                y = array(y)\n",
    "                print(dataset, bb, y)\n",
    "                \n",
    "                candidate_measure = 'r2'\n",
    "                candidate_measure = 'r²' if candidate_measure == 'r2' else candidate_measure\n",
    "                if np.isnan(y).any():\n",
    "                    nan_index = np.argwhere(np.isnan(y)).squeeze().item(0)\n",
    "                    x, y = x[:nan_index], y[:nan_index]\n",
    "                    x = x[:y.shape[0]]\n",
    "                argmax_y = np.where(y == y.max())[0][-1]\n",
    "\n",
    "                # Data labels\n",
    "                source = ColumnDataSource(data=dict(x=x, y=y, names=[str(y_)[:4] for y_ in y]))\n",
    "                computed_source = ColumnDataSource(data=dict(x=x, y=y))\n",
    "                best_source = ColumnDataSource(data=dict(x=[x[argmax_y]], y=[y[argmax_y]]))\n",
    "\n",
    "                # Available data\n",
    "                line = p.line(x='x', y='y', line_width=4, alpha=.5,\n",
    "                              line_color=color, source=computed_source, line_dash='dashed')\n",
    "                dots = getattr(p, shape)(x='x', y='y', size=16, line_width=2, color=color,\n",
    "                                         source=computed_source)\n",
    "                legend_entries.append((adv if adv != 'r2' else 'RRS', [dots]))\n",
    "                \n",
    "                if foo != 'coverage':\n",
    "                    dots = getattr(p, shape)(x='x', y='y', size=32, line_width=2, color=color, fill_alpha=0,\n",
    "                                             source=best_source)\n",
    "\n",
    "            # Legend\n",
    "            legend = Legend(items=legend_entries, location=(0, 0))\n",
    "            legend.label_text_font_size = '20pt'\n",
    "            legend.orientation = 'horizontal'\n",
    "            legend.click_policy=\"mute\"\n",
    "            p.add_layout(legend, 'above')\n",
    "            p.legend.glyph_height = 30\n",
    "            p.legend.glyph_width = 30\n",
    "            p.toolbar.logo = None\n",
    "            p.toolbar_location = None\n",
    "            \n",
    "            #p.legend.location = 'top_left'\n",
    "            #p.legend[0].orientation = legend_orientation\n",
    "            #p.legend.label_text_font_size = '20pt'\n",
    "            #p.legend.background_fill_alpha = 0.\n",
    "\n",
    "            export_png(p, filename='size-' + dataset + '-' + foo + '-' + bb + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fidelity\n",
      "coverage\n",
      "hmean\n",
      "fidelity\n",
      "coverage\n",
      "hmean\n",
      "fidelity\n",
      "coverage\n",
      "hmean\n",
      "fidelity\n",
      "coverage\n",
      "hmean\n",
      "fidelity\n",
      "coverage\n",
      "hmean\n",
      "fidelity\n",
      "coverage\n",
      "hmean\n",
      "fidelity\n",
      "coverage\n",
      "hmean\n",
      "fidelity\n",
      "coverage\n",
      "hmean\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import hmean\n",
    "\n",
    "def hmean_(a, b):\n",
    "    return 0 if a == 0 or b == 0 else hmean([a, b])\n",
    "\n",
    "hmeans = [hmean_(a, b) for a, b in full_adversaries_results[['beta-scoring-fidelity', 'beta-scoring-coverage']].values]\n",
    "full_adversaries_results['beta-scoring-hmean'] = hmeans\n",
    "hmeans = [hmean_(a, b) for a, b in full_results[['beta-scoring-fidelity', 'beta-scoring-coverage']].values]\n",
    "full_results['beta-scoring-hmean'] = hmeans\n",
    "\n",
    "draw_left_axis_label = True\n",
    "legend_position = 'bottom_left'\n",
    "legend_orientation = 'horizontal'\n",
    "name = None\n",
    "\n",
    "plt_colors3 = ['#009988', '#004488', '#ddaa33', '#bb5566', '#000000']\n",
    "for bb in black_boxes:\n",
    "    for dataset in datasets:\n",
    "        for foo in ['fidelity', 'coverage', 'hmean']:\n",
    "            draw_left_axis_label = True\n",
    "\n",
    "            # Plot\n",
    "            p = figure(x_axis_type='linear', x_minor_ticks=5, plot_width=600, plot_height=400,\n",
    "                      title=dataset.capitalize() + ' - ' + bb.upper())\n",
    "            p.title.text_font_size = '25pt'\n",
    "\n",
    "            # Axes\n",
    "            p.xaxis[0].ticker.desired_num_ticks = 5\n",
    "            p.yaxis[0].ticker.desired_num_ticks = 6\n",
    "            p.xaxis[0].axis_label_text_font_size = '25pt'\n",
    "            p.yaxis[0].axis_label_text_font_size = '25pt'\n",
    "            p.xaxis[0].major_label_text_font_size = '25pt'\n",
    "            p.yaxis[0].major_label_text_font_size = '25pt'\n",
    "            p.xaxis.axis_label = 'β'\n",
    "            p.yaxis.axis_label = foo.capitalize()\n",
    "            p.xaxis.major_tick_line_color = None  # turn off x-axis major ticks\n",
    "            p.xaxis.minor_tick_line_color = None  # turn off x-axis minor ticks\n",
    "            p.yaxis.major_tick_line_color = None  # turn off y-axis major ticks\n",
    "            p.yaxis.minor_tick_line_color = None  # turn off y-axis minor ticks\n",
    "            p.yaxis[0].formatter = NumeralTickFormatter(format=\"0.0\")\n",
    "            \n",
    "            legend_entries = []\n",
    "            \n",
    "            # Draw union baseline, i.e. cut on beta = 0\n",
    "            df_prime = full_adversaries_results[(full_adversaries_results.black_box == bb)\\\n",
    "                                                & (full_adversaries_results.dataset == dataset)\\\n",
    "                                                & (full_adversaries_results.scoring == 'r2')\\\n",
    "                                                & (full_adversaries_results.beta == 0)]\n",
    "            base_y = df_prime['scoring-fidelities'].values.item(0)\n",
    "            # p.line(x=[left, right], y=[base_y, base_y], line_width=2, color=BLACK, alpha=.5, line_dash='dashed', legend='no pruning')\n",
    "            \n",
    "            print(foo)\n",
    "            for adv, shape, color in zip(adversaries + ['r2'], shapes, plt_colors3):     \n",
    "                if dataset == 'german' and adv == 'corels':\n",
    "                    continue\n",
    "                measure = foo\n",
    "                x = [0, 50, 75, 90, 99]\n",
    "                if adv != 'r2':\n",
    "                    df = full_adversaries_results[(full_adversaries_results.scoring == 'r2')\\\n",
    "                                                  & (full_adversaries_results.dataset == dataset)\\\n",
    "                                                  & (full_adversaries_results.black_box == bb)\n",
    "                                                 & (full_adversaries_results.algorithm == adv)]\\\n",
    "                                                .groupby(['beta', 'algorithm'])\\\n",
    "                        [['beta-scoring-' + foo]].mean()\n",
    "                    y = [df.loc[b, adv].values.item(0) for b in [0, 50, 75, 90, 99]]\n",
    "                else:\n",
    "                    df = full_results[(full_results.scoring == 'r2')\\\n",
    "                                      & (full_results.dataset == dataset)]\\\n",
    "                                        .groupby(['beta', 'black_box', 'dataset'])\\\n",
    "                        [['beta-scoring-' + foo]].mean()\n",
    "                    y = [df.loc[b, bb, dataset].values.item(0) for b in [0, 50, 75, 90, 99]]\n",
    "                y = array(y)\n",
    "\n",
    "                # Plot borders\n",
    "                left, right, bottom, top = -9, 109, -0.1, 1.1\n",
    "                p.x_range = Range1d(left, right)\n",
    "                p.y_range = Range1d(bottom, top)\n",
    "\n",
    "                candidate_measure = 'r2'\n",
    "                candidate_measure = 'r²' if candidate_measure == 'r2' else candidate_measure\n",
    "                if np.isnan(y).any():\n",
    "                    nan_index = np.argwhere(np.isnan(y)).squeeze().item(0)\n",
    "                    x, y = x[:nan_index], y[:nan_index]\n",
    "                    x = x[:y.shape[0]]\n",
    "                argmax_y = np.where(y == y.max())[0][-1]\n",
    "\n",
    "                # Data labels\n",
    "                source = ColumnDataSource(data=dict(x=x, y=y, names=[str(y_)[:4] for y_ in y]))\n",
    "                computed_source = ColumnDataSource(data=dict(x=x, y=y))\n",
    "                best_source = ColumnDataSource(data=dict(x=[x[argmax_y]], y=[y[argmax_y]]))\n",
    "\n",
    "                # Available data\n",
    "                line = p.line(x='x', y='y', line_width=4, alpha=.5,\n",
    "                              line_color=color, source=computed_source, line_dash='dashed')\n",
    "                dots = getattr(p, shape)(x='x', y='y', size=16, line_width=2, color=color,\n",
    "                                         source=computed_source)\n",
    "                legend_entries.append((adv.upper() if adv != 'r2' else 'RRS', [dots]))\n",
    "                \n",
    "                if foo != 'coverage':\n",
    "                    dots = getattr(p, shape)(x='x', y='y', size=32, line_width=2, color=color, fill_alpha=0,\n",
    "                                             source=best_source)\n",
    "\n",
    "            # Legend\n",
    "            legend = Legend(items=legend_entries, location=(0, 0))\n",
    "            legend.label_text_font_size = '20pt'\n",
    "            legend.orientation = 'horizontal'\n",
    "            legend.click_policy=\"mute\"\n",
    "            p.add_layout(legend, 'above')\n",
    "            p.legend.glyph_height = 30\n",
    "            p.legend.glyph_width = 30\n",
    "            p.toolbar.logo = None\n",
    "            p.toolbar_location = None\n",
    "            \n",
    "            #p.legend.location = 'top_left'\n",
    "            #p.legend[0].orientation = legend_orientation\n",
    "            #p.legend.label_text_font_size = '20pt'\n",
    "            #p.legend.background_fill_alpha = 0.\n",
    "\n",
    "            export_png(p, filename='global-' + dataset + '-' + foo + '-' + bb + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fidelity\n",
      "coverage\n",
      "hmean\n",
      "fidelity\n",
      "coverage\n",
      "hmean\n",
      "fidelity\n",
      "coverage\n",
      "hmean\n",
      "fidelity\n",
      "coverage\n",
      "hmean\n",
      "fidelity\n",
      "coverage\n",
      "hmean\n",
      "fidelity\n",
      "coverage\n",
      "hmean\n",
      "fidelity\n",
      "coverage\n",
      "hmean\n",
      "fidelity\n",
      "coverage\n",
      "hmean\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import hmean\n",
    "\n",
    "def hmean_(a, b):\n",
    "    return 0 if a == 0 or b == 0 else hmean([a, b])\n",
    "\n",
    "hmeans = [hmean_(a, b) for a, b in full_results[['beta-scoring-fidelity', 'beta-scoring-coverage']].values]\n",
    "full_results['beta-scoring-hmean'] = hmeans\n",
    "hmeans = [hmean_(a, b) for a, b in full_results[['beta-scoring-fidelity', 'beta-scoring-coverage']].values]\n",
    "full_results['beta-scoring-hmean'] = hmeans\n",
    "\n",
    "draw_left_axis_label = True\n",
    "legend_position = 'bottom_left'\n",
    "legend_orientation = 'horizontal'\n",
    "name = None\n",
    "names = {'fidelity': 'FS', 'coverage': 'CS', 'r2': 'RRS'}\n",
    "\n",
    "plt_colors3 = ['#009988', '#004488', '#bb5566', '#000000', '#ddaa33']\n",
    "for bb in black_boxes:\n",
    "    for dataset in datasets:\n",
    "        for foo in ['fidelity', 'coverage', 'hmean']:\n",
    "            draw_left_axis_label = foo == 'fidelity'\n",
    "\n",
    "            # Plot\n",
    "            p = figure(x_axis_type='linear', x_minor_ticks=5, plot_width=600, plot_height=400,\n",
    "                      title=dataset.capitalize() + ' - ' + bb.upper())\n",
    "            # p.output_backend = 'svg'\n",
    "            p.title.text_font_size = '25pt'\n",
    "\n",
    "            # Axes\n",
    "            p.xaxis[0].ticker.desired_num_ticks = 5\n",
    "            p.yaxis[0].ticker.desired_num_ticks = 5\n",
    "            p.xaxis[0].axis_label_text_font_size = '25pt'\n",
    "            p.yaxis[0].axis_label_text_font_size = '25pt'\n",
    "            p.xaxis[0].major_label_text_font_size = '25pt'\n",
    "            p.yaxis[0].major_label_text_font_size = '25pt'\n",
    "            p.xaxis.axis_label = 'β'\n",
    "            p.yaxis.axis_label = foo.capitalize()\n",
    "            p.xaxis.major_tick_line_color = None  # turn off x-axis major ticks\n",
    "            p.xaxis.minor_tick_line_color = None  # turn off x-axis minor ticks\n",
    "            p.yaxis.major_tick_line_color = None  # turn off y-axis major ticks\n",
    "            p.yaxis.minor_tick_line_color = None  # turn off y-axis minor ticks\n",
    "            p.yaxis[0].formatter = NumeralTickFormatter(format=\"0.0\")\n",
    "            \n",
    "            legend_entries = []\n",
    "            \n",
    "            # Draw union baseline, i.e. cut on beta = 0\n",
    "            df_prime = full_results[(full_results.black_box == bb)\\\n",
    "                                                & (full_results.dataset == dataset)\\\n",
    "                                                & (full_results.scoring == 'r2')\\\n",
    "                                                & (full_results.beta == 0)]\n",
    "            base_y = df_prime['scoring-fidelities'].values.item(0)\n",
    "            # p.line(x=[left, right], y=[base_y, base_y], line_width=2, color=BLACK, alpha=.5, line_dash='dashed', legend='no pruning')\n",
    "            \n",
    "            print(foo)\n",
    "            for scoring, shape, color in zip(['coverage', 'fidelity', 'r2'], shapes, plt_colors3):\n",
    "                measure = foo\n",
    "                measure_name = names[scoring]\n",
    "                x = [0, 25, 50, 75, 90, 99]\n",
    "                df = full_results[(full_results.scoring == scoring)\\\n",
    "                                  & (full_results.dataset == dataset)\\\n",
    "                                  & (full_results.black_box == bb)].groupby('beta').mean()\n",
    "                y = df['beta-scoring-' + foo].values\n",
    "\n",
    "                # Plot borders\n",
    "                left, right, bottom, top = -9, 109, -0.1, 1.09\n",
    "                p.x_range = Range1d(left, right)\n",
    "                p.y_range = Range1d(bottom, top)\n",
    "\n",
    "                candidate_measure = 'r2'\n",
    "                candidate_measure = 'r²' if candidate_measure == 'r2' else candidate_measure\n",
    "                if np.isnan(y).any():\n",
    "                    nan_index = np.argwhere(np.isnan(y)).squeeze().item(0)\n",
    "                    x, y = x[:nan_index], y[:nan_index]\n",
    "                    x = x[:y.shape[0]]\n",
    "                argmax_y = np.where(y == y.max())[0][-1]\n",
    "\n",
    "                # Data labels\n",
    "                source = ColumnDataSource(data=dict(x=x, y=y, names=[str(y_)[:4] for y_ in y]))\n",
    "                computed_source = ColumnDataSource(data=dict(x=x, y=y))\n",
    "                best_source = ColumnDataSource(data=dict(x=[x[argmax_y]], y=[y[argmax_y]]))\n",
    "\n",
    "                # Available data\n",
    "                line = p.line(x='x', y='y', line_width=4, alpha=.5,\n",
    "                              line_color=color, source=computed_source, line_dash='dashed')\n",
    "                dots = getattr(p, shape)(x='x', y='y', size=16, line_width=2, color=color,\n",
    "                                         source=computed_source, legend=measure_name)\n",
    "                legend_entries.append((scoring, [dots]))\n",
    "                \n",
    "                if foo != 'coverage':\n",
    "                    dots = getattr(p, shape)(x='x', y='y', size=32, line_width=2, color=color, fill_alpha=0,\n",
    "                                             source=best_source)\n",
    "\n",
    "            # Legend\n",
    "            p.legend.label_text_font_size = '25pt'\n",
    "            p.legend.orientation = 'vertical'\n",
    "            p.legend.location = 'bottom_left'\n",
    "            p.legend.background_fill_alpha = .5\n",
    "            p.legend.glyph_height = 30\n",
    "            p.legend.glyph_width = 30         \n",
    "            p.toolbar.logo = None\n",
    "            p.toolbar_location = None\n",
    "\n",
    "            export_png(p, 'scoring-' + dataset + '-' + foo + '-' + bb + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top\n",
      "1800.25\n",
      "rule_nr\n",
      "adult dnn corels\n",
      "adult dnn [1 1 1 1 1 1]\n",
      "adult dnn cpar\n",
      "adult dnn [299 224 150  75  30   3]\n",
      "adult dnn sbrl\n",
      "adult dnn [24 18 12  6  3  1]\n",
      "adult dnn r2\n",
      "adult dnn [1324  993  662  331  133   14]\n",
      "top\n",
      "275.25\n",
      "rule_nr\n",
      "churn dnn corels\n",
      "churn dnn [3 2 2 1 1 1]\n",
      "churn dnn cpar\n",
      "churn dnn [94 71 48 24 12  2]\n",
      "churn dnn sbrl\n",
      "churn dnn [6 4 3 2 1 1]\n",
      "churn dnn r2\n",
      "churn dnn [201 151 101  51  21   4]\n",
      "top\n",
      "2807.75\n",
      "rule_nr\n",
      "compas dnn corels\n",
      "compas dnn [1 1 1 1 1 1]\n",
      "compas dnn cpar\n",
      "compas dnn [2247 1686 1124  562  227   72]\n",
      "compas dnn sbrl\n",
      "compas dnn [7 7 7 2 1 1]\n",
      "compas dnn r2\n",
      "compas dnn [232 174 116  58  24   3]\n",
      "top\n",
      "146.5\n",
      "rule_nr\n",
      "german dnn cpar\n",
      "german dnn [26 19 13  7  3  1]\n",
      "german dnn sbrl\n",
      "german dnn [2 2 2 2 2 2]\n",
      "german dnn r2\n",
      "german dnn [84 63 42 21  9  1]\n",
      "top\n",
      "1800.25\n",
      "rule_nr\n",
      "adult rf corels\n",
      "adult rf [1 1 1 1 1 1]\n",
      "adult rf cpar\n",
      "adult rf [85 64 43 22  9  1]\n",
      "adult rf sbrl\n",
      "adult rf [26 20 13  7  3  1]\n",
      "adult rf r2\n",
      "adult rf [1441 1081  721  361  146   17]\n",
      "top\n",
      "275.25\n",
      "rule_nr\n",
      "churn rf corels\n",
      "churn rf [1 1 1 1 1 1]\n",
      "churn rf cpar\n",
      "churn rf [130  97  66  35  13   2]\n",
      "churn rf sbrl\n",
      "churn rf [6 6 6 6 1 1]\n",
      "churn rf r2\n",
      "churn rf [221 166 111  56  23   3]\n",
      "top\n",
      "399.0\n",
      "rule_nr\n",
      "compas rf corels\n",
      "compas rf [2 1 1 1 1 1]\n",
      "compas rf cpar\n",
      "compas rf [44 33 22 11  5  1]\n",
      "compas rf sbrl\n",
      "compas rf [5 5 3 2 1 1]\n",
      "compas rf r2\n",
      "compas rf [320 240 160  82  32   5]\n",
      "top\n",
      "146.5\n",
      "rule_nr\n",
      "german rf cpar\n",
      "german rf [18 13  9  5  2  1]\n",
      "german rf sbrl\n",
      "german rf [6 4 3 2 1 1]\n",
      "german rf r2\n",
      "german rf [118  88  59  30  12   2]\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import hmean\n",
    "\n",
    "def hmean_(a, b):\n",
    "    return 0 if a == 0 or b == 0 else hmean([a, b])\n",
    "\n",
    "hmeans = [hmean_(a, b) for a, b in full_adversaries_results[['beta-scoring-fidelity', 'beta-scoring-coverage']].values]\n",
    "full_adversaries_results['beta-scoring-hmean'] = hmeans\n",
    "hmeans = [hmean_(a, b) for a, b in full_results[['beta-scoring-fidelity', 'beta-scoring-coverage']].values]\n",
    "full_results['beta-scoring-hmean'] = hmeans\n",
    "\n",
    "draw_left_axis_label = True\n",
    "legend_position = 'bottom_left'\n",
    "legend_orientation = 'horizontal'\n",
    "name = None\n",
    "\n",
    "plt_colors3 = ['#009988', '#004488', '#ddaa33', '#bb5566', '#000000']\n",
    "for bb in black_boxes:\n",
    "    for dataset in datasets:\n",
    "        top_ = full_adversaries_results[(full_adversaries_results.dataset == dataset)\\\n",
    "                                       & (full_adversaries_results.black_box == bb)]['beta-scoring-rule_nr'].values.max()\n",
    "        top_ = max(top_, full_results[(full_results.scoring == 'r2') & (full_results.dataset == dataset)]['beta-scoring-rule_nr'].values.max())\n",
    "        bottom_ = - (top_ / p.yaxis[0].ticker.desired_num_ticks + 1)\n",
    "        top_ = top_ + (top_ / p.yaxis[0].ticker.desired_num_ticks - 1)\n",
    "        \n",
    "        \n",
    "        # Plot borders\n",
    "        left, right, bottom, top = -9, 109, bottom_, top_\n",
    "        print('top')\n",
    "        print(top)\n",
    "        for foo in ['rule_nr']:\n",
    "            draw_left_axis_label = True\n",
    "\n",
    "            # Plot\n",
    "            p = figure(x_axis_type='linear', x_minor_ticks=5, plot_width=600, plot_height=400,\n",
    "                      title=dataset.capitalize() + ' - ' + bb.upper())\n",
    "            p.title.text_font_size = '25pt'\n",
    "\n",
    "            # Axes\n",
    "            p.xaxis[0].ticker.desired_num_ticks = 5\n",
    "            p.yaxis[0].ticker.desired_num_ticks = 4\n",
    "            p.xaxis[0].axis_label_text_font_size = '25pt'\n",
    "            p.yaxis[0].axis_label_text_font_size = '25pt'\n",
    "            p.xaxis[0].major_label_text_font_size = '25pt'\n",
    "            p.yaxis[0].major_label_text_font_size = '25pt'\n",
    "            p.xaxis.axis_label = 'β'\n",
    "            p.yaxis.axis_label = '#rules'\n",
    "            p.xaxis.major_tick_line_color = None  # turn off x-axis major ticks\n",
    "            p.xaxis.minor_tick_line_color = None  # turn off x-axis minor ticks\n",
    "            p.yaxis.major_tick_line_color = None  # turn off y-axis major ticks\n",
    "            p.yaxis.minor_tick_line_color = None  # turn off y-axis minor ticks\n",
    "            p.x_range = Range1d(left, right)\n",
    "            p.y_range = Range1d(bottom, top)\n",
    "            \n",
    "            legend_entries = []\n",
    "            \n",
    "            # Draw union baseline, i.e. cut on beta = 0\n",
    "            df_prime = full_adversaries_results[(full_adversaries_results.black_box == bb)\\\n",
    "                                                & (full_adversaries_results.dataset == dataset)\\\n",
    "                                                & (full_adversaries_results.scoring == 'r2')\\\n",
    "                                                & (full_adversaries_results.beta == 0)]\n",
    "            base_y = df_prime['scoring-fidelities'].values.item(0)\n",
    "            # p.line(x=[left, right], y=[base_y, base_y], line_width=2, color=BLACK, alpha=.5, line_dash='dashed', legend='no pruning')\n",
    "            \n",
    "            print(foo)\n",
    "            for adv, shape, color in zip(adversaries + ['r2'], shapes, plt_colors3):     \n",
    "                if dataset == 'german' and adv == 'corels':\n",
    "                    continue\n",
    "                measure = foo\n",
    "                print(dataset, bb, adv)\n",
    "                x = [0, 25, 50, 75, 90, 99]\n",
    "                if adv != 'r2':\n",
    "                    df = full_adversaries_results[(full_adversaries_results.scoring == 'r2')\\\n",
    "                                                  & (full_adversaries_results.dataset == dataset)\\\n",
    "                                                  & (full_adversaries_results.black_box == bb)\n",
    "                                                 & (full_adversaries_results.algorithm == adv)]\\\n",
    "                                                .groupby(['beta', 'algorithm'])\\\n",
    "                        [['beta-scoring-' + foo]].mean()\n",
    "                    y = [df.loc[b, adv].values.item(0) for b in x]\n",
    "                else:\n",
    "                    df = full_results[(full_results.scoring == 'r2')\\\n",
    "                                      & (full_results.dataset == dataset)]\\\n",
    "                                        .groupby(['beta', 'black_box', 'dataset'])\\\n",
    "                        [['beta-scoring-' + foo]].mean()\n",
    "                    y = [df.loc[b, bb, dataset].values.item(0) for b in x]\n",
    "                y = array(y)\n",
    "                print(dataset, bb, y)\n",
    "                \n",
    "                candidate_measure = 'r2'\n",
    "                candidate_measure = 'r²' if candidate_measure == 'r2' else candidate_measure\n",
    "                if np.isnan(y).any():\n",
    "                    nan_index = np.argwhere(np.isnan(y)).squeeze().item(0)\n",
    "                    x, y = x[:nan_index], y[:nan_index]\n",
    "                    x = x[:y.shape[0]]\n",
    "                argmax_y = np.where(y == y.max())[0][-1]\n",
    "\n",
    "                # Data labels\n",
    "                source = ColumnDataSource(data=dict(x=x, y=y, names=[str(y_)[:4] for y_ in y]))\n",
    "                computed_source = ColumnDataSource(data=dict(x=x, y=y))\n",
    "                best_source = ColumnDataSource(data=dict(x=[x[argmax_y]], y=[y[argmax_y]]))\n",
    "\n",
    "                # Available data\n",
    "                line = p.line(x='x', y='y', line_width=4, alpha=.5,\n",
    "                              line_color=color, source=computed_source, line_dash='dashed')\n",
    "                dots = getattr(p, shape)(x='x', y='y', size=16, line_width=2, color=color,\n",
    "                                         source=computed_source)\n",
    "                legend_entries.append((adv.upper() if adv != 'r2' else 'RRS', [dots]))\n",
    "                \n",
    "                if foo != 'coverage':\n",
    "                    dots = getattr(p, shape)(x='x', y='y', size=32, line_width=2, color=color, fill_alpha=0,\n",
    "                                             source=best_source)\n",
    "\n",
    "            # Legend\n",
    "            legend = Legend(items=legend_entries, location=(0, 0))\n",
    "            legend.label_text_font_size = '15pt'\n",
    "            legend.orientation = 'horizontal'\n",
    "            p.add_layout(legend, 'above')\n",
    "            p.legend.glyph_height = 30\n",
    "            p.legend.glyph_width = 30\n",
    "            p.toolbar.logo = None\n",
    "            p.toolbar_location = None\n",
    "            \n",
    "            #p.legend.location = 'top_left'\n",
    "            #p.legend[0].orientation = legend_orientation\n",
    "            #p.legend.label_text_font_size = '20pt'\n",
    "            #p.legend.background_fill_alpha = 0.\n",
    "\n",
    "            export_png(p, filename='size-' + dataset + '-' + foo + '-' + bb + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beta-scoring-hmean</th>\n",
       "      <th>beta-scoring-rule_nr</th>\n",
       "      <th>mean-beta-scoring-length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.290613</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.246498</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.556272</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.474393</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    beta-scoring-hmean  beta-scoring-rule_nr  mean-beta-scoring-length\n",
       "5             0.290613                  26.0                       1.0\n",
       "11            0.246498                   6.0                       1.0\n",
       "17            0.556272                   5.0                       1.0\n",
       "21            0.474393                   6.0                       1.0"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import hmean\n",
    "\n",
    "def hmean_(a, b):\n",
    "    return 0 if a == 0 or b == 0 else hmean([a, b])\n",
    "\n",
    "hmeans = [hmean_(a, b) for a, b in full_adversaries_results[['beta-scoring-fidelity', 'beta-scoring-coverage']].values]\n",
    "full_adversaries_results['beta-scoring-hmean'] = hmeans\n",
    "hmeans = [hmean_(a, b) for a, b in full_results[['beta-scoring-fidelity', 'beta-scoring-coverage']].values]\n",
    "full_results['beta-scoring-hmean'] = hmeans\n",
    "df1 = full_adversaries_results[(full_adversaries_results.scoring == 'r2')\\\n",
    "                               & (full_adversaries_results.beta == 0)].groupby(['dataset', 'black_box', 'algorithm']).mean()\\\n",
    "                                [['beta-scoring-rule_nr', 'mean-beta-scoring-length', 'beta-scoring-hmean']]\n",
    "full_results['algorithm'] = 'scoring'\n",
    "df2 = full_results[(full_results.scoring == 'r2')\\\n",
    "                   & (full_results.beta == 75)].groupby(['dataset', 'black_box', 'algorithm']).mean()\\\n",
    "                    [['beta-scoring-rule_nr', 'mean-beta-scoring-length', 'beta-scoring-hmean']]\n",
    "\n",
    "df = pd.concat([df1.reset_index(), df2.reset_index()], ignore_index=True).sort_values(['dataset', 'black_box'])\n",
    "df[(df.black_box == 'rf') & (df.algorithm == 'sbrl')][['beta-scoring-hmean', 'beta-scoring-rule_nr', 'mean-beta-scoring-length']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['dataset', 'black_box', 'scoring', 'k', 'alpha', 'beta', 'gamma',\n",
       "       'max_len', 'scoring-fidelities', 'beta-scoring-fidelity',\n",
       "       'beta-scoring-rule_nr', 'coverage', 'beta-scoring-coverage',\n",
       "       'mean_length', 'std_length', 'mean-beta-scoring-length',\n",
       "       'std-beta-scoring-length', 'mean_prediction', 'std-scoring-prediction',\n",
       "       'rule_reduction-beta-scoring', 'len_reduction-beta-scoring',\n",
       "       'simplicity-beta-scoring', 'feature_frequency',\n",
       "       'scoring-beta-feature_frequency', 'beta-scoring-hmean', 'algorithm'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_results.columns.be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import hmean\n",
    "\n",
    "def hmean_(a, b):\n",
    "    return 0 if a == 0 or b == 0 else hmean([a, b])\n",
    "\n",
    "hmeans = [hmean_(a, b) for a, b in full_adversaries_results[['beta-scoring-fidelity', 'beta-scoring-coverage']].values]\n",
    "full_adversaries_results['hmean'] = hmeans\n",
    "hmeans = [hmean_(a, b) for a, b in full_results[['beta-scoring-fidelity', 'beta-scoring-coverage']].values]\n",
    "full_results['hmean'] = hmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from more_itertools import flatten\n",
    "\n",
    "dfs = []\n",
    "for d in datasets:\n",
    "    df = full_adversaries_results[(full_adversaries_results.dataset == d)\\\n",
    "                                  & (full_adversaries_results.black_box == 'dnn')]\\\n",
    "        .groupby(['algorithm', 'dataset', 'beta'])['beta-scoring-rule_nr'].describe()[['mean', 'std']]\n",
    "    df = df.reset_index()\n",
    "    dfs.append(df)\n",
    "\n",
    "df = pd.concat(dfs, axis='columns', ignore_index=True)\n",
    "df = df.drop([5, 7, 10, 12, 15, 17], axis='columns')\n",
    "df.columns = ['Algorithm', 'dataset1', 'beta', 'mean1', 'std1',\n",
    "              'dataset2', 'mean2', 'std2',\n",
    "              'dataset3', 'mean3', 'std3',\n",
    "              'dataset4', 'mean4', 'std4']\n",
    "for d, i in zip(datasets, range(1, 5)):\n",
    "    df[d + ' $\\mu \\pm \\sigma$'] = str(df['mean' + str(i)]) + ' \\pm ' + str(df['std' + str(i)])\n",
    "\n",
    "df_1 = df[~df.dataset1.isin({'churn', 'compas', 'german'})][['Algorithm', 'beta', 'dataset1', 'mean1', 'std1', 'adult $\\mu \\pm \\sigma$']]\n",
    "df_2 = df[~df.dataset2.isin({'adult', 'compas', 'german'})][['Algorithm', 'beta', 'dataset2', 'mean2', 'std2', 'churn $\\mu \\pm \\sigma$']]\n",
    "df_3 = df[~df.dataset3.isin({'adult', 'churn', 'german'})][['Algorithm', 'beta', 'dataset3', 'mean3', 'std3', 'compas $\\mu \\pm \\sigma$']]\n",
    "df_4 = df[~df.dataset4.isin({'adult', 'churn', 'compas'})][['Algorithm', 'beta', 'dataset4', 'mean4', 'std4', 'german $\\mu \\pm \\sigma$']]\n",
    "\n",
    "df_1['$\\mu \\pm \\sigma$'] = df_1[['mean1', 'std1']].apply(lambda x: '$' + str(x.mean1)[:4] + ' \\pm '  + str(x.std1)[:4] + '$' if not np.isnan(x.mean1) else '-', axis='columns')\n",
    "df_2['$\\mu \\pm \\sigma$'] = df_2[['mean2', 'std2']].apply(lambda x: '$' + str(x.mean2)[:4] + ' \\pm '  + str(x.std2)[:4] + '$' if not np.isnan(x.mean2) else '-', axis='columns')\n",
    "df_3['$\\mu \\pm \\sigma$'] = df_3[['mean3', 'std3']].apply(lambda x: '$' + str(x.mean3)[:4] + ' \\pm '  + str(x.std3)[:4] + '$' if not np.isnan(x.mean3) else '-', axis='columns')\n",
    "df_4['$\\mu \\pm \\sigma$'] = df_4[['mean4', 'std4']].apply(lambda x: '$' + str(x.mean4)[:4] + ' \\pm '  + str(x.std4)[:4] + '$' if not np.isnan(x.mean4) else '-', axis='columns')\n",
    "\n",
    "df_1.columns = ['alg', '$\\beta$', 'dataset', 'del1', 'del2', 'del3', '$\\mu \\pm \\sigma$']\n",
    "df_1 = df_1[['dataset', 'alg', '$\\beta$', '$\\mu \\pm \\sigma$']]\n",
    "\n",
    "df_2.columns = ['alg', '$\\beta$', 'dataset', 'del1', 'del2', 'del3', '$\\mu \\pm \\sigma$']\n",
    "df_2 = df_2[['dataset', 'alg', '$\\beta$', '$\\mu \\pm \\sigma$']]\n",
    "\n",
    "df_3.columns = ['alg', '$\\beta$', 'dataset', 'del1', 'del2', 'del3', '$\\mu \\pm \\sigma$']\n",
    "df_3 = df_3[['dataset', 'alg', '$\\beta$', '$\\mu \\pm \\sigma$']]\n",
    "\n",
    "df_4.columns = ['alg', '$\\beta$', 'dataset', 'del1', 'del2', 'del3', '$\\mu \\pm \\sigma$']\n",
    "df_4 = df_4[['dataset', 'alg', '$\\beta$', '$\\mu \\pm \\sigma$']]\n",
    "\n",
    "df_tot = pd.concat([df_1, df_2, df_3, df_4], axis='columns', ignore_index=True)\n",
    "df_tot.columns = list(flatten([['d{0}'.format(i), 'alg{0}'.format(i), 'beta{0}'.format(i), 'v{0}'.format(i)] for i in range(4)]))\n",
    "df_tot = df_tot.drop(['alg1', 'alg2', 'alg3', 'beta1', 'beta2', 'beta3'], axis='columns')\n",
    "df_tot.columns = ['alg', '$beta$', 'dataset', '$\\mu \\pm \\sigma$', 'dataset', '$\\mu \\pm \\sigma$', 'dataset', '$\\mu \\pm \\sigma$', 'dataset', '$\\mu \\pm \\sigma$']\n",
    "\n",
    "table = str(df_tot.to_latex(escape=False))\n",
    "table = table.replace('toprule', 'hline').replace('midrule', 'hline').replace('bottomrule', 'hline')\n",
    "table = table.replace('0.00 &', '0 &').replace('25.00 &', '25 &').replace('50.00 &', '50 &').replace('75.00 &', '75 &').replace('90.00 &', '90 &').replace('99.00 &', '99 &')\n",
    "table = table.replace('beta', '\\beta')\n",
    "print(table)\n",
    "df_tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for d in [df_1, df_2, df_3, df_4]:\n",
    "    print(d.iloc[:, -1].to_latex(escape=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from more_itertools import flatten\n",
    "\n",
    "dfs = []\n",
    "for d in datasets:\n",
    "    df = full_adversaries_results[(full_adversaries_results.dataset == d)\\\n",
    "                                  & (full_adversaries_results.black_box == 'rf')]\\\n",
    "        .groupby(['algorithm', 'dataset', 'beta'])['beta-scoring-rule_nr'].describe()[['mean', 'std']]\n",
    "    df = df.reset_index()\n",
    "    print(df.shape)\n",
    "    dfs.append(df)\n",
    "\n",
    "df = pd.concat(dfs, axis='columns', ignore_index=True)\n",
    "df = df.drop([5, 7, 10, 12, 15, 17], axis='columns')\n",
    "df.columns = ['Algorithm', 'dataset1', 'beta', 'mean1', 'std1',\n",
    "              'dataset2', 'mean2', 'std2',\n",
    "              'dataset3', 'mean3', 'std3',\n",
    "              'dataset4', 'mean4', 'std4']\n",
    "\n",
    "for d, i in zip(datasets, range(1, 5)):\n",
    "    df[d + ' $\\mu \\pm \\sigma$'] = str(df['mean' + str(i)]) + ' \\pm ' + str(df['std' + str(i)])\n",
    "\n",
    "df_1 = df[~df.dataset1.isin({'churn', 'compas', 'german'})][['Algorithm', 'beta', 'dataset1', 'mean1', 'std1', 'adult $\\mu \\pm \\sigma$']]\n",
    "df_2 = df[~df.dataset2.isin({'adult', 'compas', 'german'})][['Algorithm', 'beta', 'dataset2', 'mean2', 'std2', 'churn $\\mu \\pm \\sigma$']]\n",
    "df_3 = df[~df.dataset3.isin({'adult', 'churn', 'german'})][['Algorithm', 'beta', 'dataset3', 'mean3', 'std3', 'compas $\\mu \\pm \\sigma$']]\n",
    "df_4 = df[~df.dataset4.isin({'adult', 'churn', 'compas'})][['Algorithm', 'beta', 'dataset4', 'mean4', 'std4', 'german $\\mu \\pm \\sigma$']]\n",
    "\n",
    "print(df_1.shape)\n",
    "print(df_2.shape)\n",
    "print(df_3.shape)\n",
    "print(df_4.shape)\n",
    "\n",
    "df_1['$\\mu \\pm \\sigma$'] = df_1[['mean1', 'std1']].apply(lambda x: '$' + str(x.mean1)[:4] + ' \\pm '  + str(x.std1)[:4] + '$' if not np.isnan(x.mean1) else '-', axis='columns')\n",
    "df_2['$\\mu \\pm \\sigma$'] = df_2[['mean2', 'std2']].apply(lambda x: '$' + str(x.mean2)[:4] + ' \\pm '  + str(x.std2)[:4] + '$' if not np.isnan(x.mean2) else '-', axis='columns')\n",
    "df_3['$\\mu \\pm \\sigma$'] = df_3[['mean3', 'std3']].apply(lambda x: '$' + str(x.mean3)[:4] + ' \\pm '  + str(x.std3)[:4] + '$' if not np.isnan(x.mean3) else '-', axis='columns')\n",
    "df_4['$\\mu \\pm \\sigma$'] = df_4[['mean4', 'std4']].apply(lambda x: '$' + str(x.mean4)[:4] + ' \\pm '  + str(x.std4)[:4] + '$' if not np.isnan(x.mean4) else '-', axis='columns')\n",
    "\n",
    "print(df_1.shape)\n",
    "print(df_2.shape)\n",
    "print(df_3.shape)\n",
    "print(df_4.shape)\n",
    "\n",
    "df_1.columns = ['alg', '$\\beta$', 'dataset', 'del1', 'del2', 'del3', '$\\mu \\pm \\sigma$']\n",
    "df_1 = df_1[['dataset', 'alg', '$\\beta$', '$\\mu \\pm \\sigma$']]\n",
    "\n",
    "df_2.columns = ['alg', '$\\beta$', 'dataset', 'del1', 'del2', 'del3', '$\\mu \\pm \\sigma$']\n",
    "df_2 = df_2[['dataset', 'alg', '$\\beta$', '$\\mu \\pm \\sigma$']]\n",
    "\n",
    "df_3.columns = ['alg', '$\\beta$', 'dataset', 'del1', 'del2', 'del3', '$\\mu \\pm \\sigma$']\n",
    "df_3 = df_3[['dataset', 'alg', '$\\beta$', '$\\mu \\pm \\sigma$']]\n",
    "\n",
    "df_4.columns = ['alg', '$\\beta$', 'dataset', 'del1', 'del2', 'del3', '$\\mu \\pm \\sigma$']\n",
    "df_4 = df_4[['dataset', 'alg', '$\\beta$', '$\\mu \\pm \\sigma$']]\n",
    "\n",
    "print(df_1.shape)\n",
    "print(df_2.shape)\n",
    "print(df_3.shape)\n",
    "print(df_4.shape)\n",
    "\n",
    "df_tot = pd.concat([df_1, df_2, df_3, df_4], axis='columns', ignore_index=True)\n",
    "df_tot.columns = list(flatten([['d{0}'.format(i), 'alg{0}'.format(i), 'beta{0}'.format(i), 'v{0}'.format(i)] for i in range(4)]))\n",
    "df_tot = df_tot.drop(['alg1', 'alg2', 'alg3', 'beta1', 'beta2', 'beta3'], axis='columns')\n",
    "df_tot.columns = ['alg', '$beta$', 'dataset', '$\\mu \\pm \\sigma$', 'dataset', '$\\mu \\pm \\sigma$', 'dataset', '$\\mu \\pm \\sigma$', 'dataset', '$\\mu \\pm \\sigma$']\n",
    "\n",
    "table = str(df_tot.to_latex(escape=False))\n",
    "table = table.replace('toprule', 'hline').replace('midrule', 'hline').replace('bottomrule', 'hline')\n",
    "table = table.replace('0.00 &', '0 &').replace('25.00 &', '25 &').replace('50.00 &', '50 &').replace('75.00 &', '75 &').replace('90.00 &', '90 &').replace('99.00 &', '99 &')\n",
    "table = table.replace('beta', '\\beta')\n",
    "# print(table)\n",
    "# df_tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for d in [df_1, df_2, df_3, df_4]:\n",
    "    print(d.iloc[:, -1].to_latex(escape=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
